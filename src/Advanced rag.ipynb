{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BsrbcXm377DU"
   },
   "source": [
    "# Analysis Overview of Advanced RAG Techniques\n",
    "\n",
    "This notebook serves as a detailed analytical resource within a larger experimental study on advanced Retrieval-Augmented Generation (RAG) techniques, as detailed in our repository. It utilizes experimental outputs generated by tonic_main.py to analyze the performance and implications of these techniques.\n",
    "\n",
    "## Highlights:\n",
    "\n",
    "- **Data Insight**: Initial processing and visualization of experimental data provide a foundation for understanding the performance landscape of various RAG techniques.\n",
    "- **Statistical Validation**: We employ ANOVA and Tukey's HSD tests to statistically evaluate the performance differences across techniques, ensuring our conclusions are robust and reliable.\n",
    "- **Focused Analysis**: While encompassing a broad spectrum of RAG techniques, specific attention is given to high-impact findings and their significance within the larger context of LLM enhancement.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 你需要更换为自己的领域数据和prompt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wREKLdd771IA"
   },
   "source": [
    "## Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fDTTBdETIrJj"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the experimental data from an Excel file\n",
    "df = pd.read_excel('checkpoint_2.xlsx')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "SOdtu4IySIRC",
    "outputId": "fdff2504-5892-4732-d85a-6e429d8d42ed"
   },
   "outputs": [],
   "source": [
    "import ast\n",
    "\n",
    "# Parse the 'OverallScores' column to convert string representations of dictionaries into actual dictionaries\n",
    "try:\n",
    "    df['OverallScores'] = df['OverallScores'].apply(ast.literal_eval)\n",
    "except ValueError as e:\n",
    "    print(f\"Error encountered: {e}\")\n",
    "\n",
    "# Extract these dictionaries into separate columns and combine with the original DataFrame\n",
    "metrics_df = df['OverallScores'].apply(pd.Series)\n",
    "expanded_data = pd.concat([df.drop(columns=['OverallScores']), metrics_df], axis=1)\n",
    "\n",
    "# Display the first few rows to verify the transformation\n",
    "expanded_data.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GIdJ8req8ebN"
   },
   "source": [
    "## Visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QKxVZVVA8UVQ"
   },
   "source": [
    "### Boxplot of Retrieval Precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 918
    },
    "id": "kCPEH0FIf3Xn",
    "outputId": "13bcfb5e-bdc0-4777-d61d-ca170c29830c"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Visualization of Retrieval Precision across different experiments\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.boxplot(x='retrieval_precision', y='Experiment', data=expanded_data, palette=\"Set3\", orient='h')\n",
    "plt.title('Boxplot of Retrieval Precision by Experiment')\n",
    "plt.xlabel('Retrieval Precision')\n",
    "plt.ylabel('Experiment')\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sapUpLXo8XHs"
   },
   "source": [
    "### Boxplot of Answer Similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 918
    },
    "id": "GLR15z_1K88g",
    "outputId": "5c0d2139-718e-4456-b7ea-e24aa0fe95e1"
   },
   "outputs": [],
   "source": [
    "# Visualization of Answer Similarity across different experiments\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.boxplot(x='answer_similarity', y='Experiment', data=expanded_data, palette=\"Set3\", orient='h')\n",
    "plt.title('Boxplot of Answer Similarity by Experiment')\n",
    "plt.xlabel('Answer Similarity')\n",
    "plt.ylabel('Experiment')\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2bUYLC6s8xCl"
   },
   "source": [
    "## Statistical Analysis\n",
    "\n",
    "To statistically evaluate the differences in `retrieval_precision` and `answer_similarity` across various RAG techniques, we perform ANOVA and Tukey's Honestly Significant Difference (HSD) tests. These tests help us determine if the observed differences in metrics are statistically significant, providing a robust basis for comparing the performance of each technique.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RUciEb1V8yVI"
   },
   "source": [
    "### ANOVA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "h08LkzsEK6N1",
    "outputId": "ad8404f2-054a-4ad5-e15e-0a7b21831663"
   },
   "outputs": [],
   "source": [
    "from scipy.stats import f_oneway\n",
    "\n",
    "# ANOVA for retrieval precision and answer similarity\n",
    "groups_rp = expanded_data.groupby('Experiment')['retrieval_precision'].apply(list)\n",
    "groups_as = expanded_data.groupby('Experiment')['answer_similarity'].apply(list)\n",
    "\n",
    "anova_rp = f_oneway(*groups_rp)\n",
    "anova_as = f_oneway(*groups_as)\n",
    "\n",
    "anova_results = {\n",
    "    'Retrieval Precision': {'statistic': anova_rp.statistic, 'p-value': anova_rp.pvalue},\n",
    "    'Answer Similarity': {'statistic': anova_as.statistic, 'p-value': anova_as.pvalue}\n",
    "}\n",
    "\n",
    "anova_results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fH4YnlGc9J2m"
   },
   "source": [
    "### Tukey - all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 423
    },
    "id": "3E1zbDldTupg",
    "outputId": "b35b565e-e8b4-497a-df73-75360a0c332d"
   },
   "outputs": [],
   "source": [
    "from statsmodels.stats.multicomp import pairwise_tukeyhsd\n",
    "import pandas as pd\n",
    "\n",
    "tukey_rp = pairwise_tukeyhsd(endog=expanded_data['retrieval_precision'], groups=expanded_data['Experiment'], alpha=0.05)\n",
    "tukey_result_df = pd.DataFrame(data=tukey_rp.summary().data[1:], columns=tukey_rp.summary().data[0])\n",
    "tukey_result_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nSniOUsE9NDY"
   },
   "source": [
    "### Tukey - Naive RAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 519
    },
    "id": "J3EdItg9UKGd",
    "outputId": "9f928d42-06c6-436b-fc3b-4e62c93577bd"
   },
   "outputs": [],
   "source": [
    "# Filter Tukey HSD results to focus on specific group comparisons\n",
    "filtered_results = tukey_result_df[\n",
    "    (tukey_result_df['group1'] == \"Classic VDB + Naive RAG\") |\n",
    "    (tukey_result_df['group2'] == \"Classic VDB + Naive RAG\")\n",
    "]\n",
    "filtered_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QwtK55U9LxBz"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ye8NLENr9tiE"
   },
   "source": [
    "### Tukey - best classic vdb techniques\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 175
    },
    "id": "YDxUKcL-UebW",
    "outputId": "ed492f54-97aa-42c1-f166-2708ebd94763"
   },
   "outputs": [],
   "source": [
    "# Focus on experiments for a detailed comparison\n",
    "experiments_focus_group1 = [\n",
    "    \"Classic VDB + HyDE\",\n",
    "    \"Classic VDB + HyDE + Cohere Rerank\",\n",
    "    \"Classic VDB + HyDE + LLM Rerank\",\n",
    "    \"Classic VDB + LLM Rerank\"\n",
    "]\n",
    "\n",
    "filtered_results = tukey_result_df[\n",
    "    tukey_result_df['group1'].isin(experiments_focus_group1) &\n",
    "    (tukey_result_df['group2'] == \"Classic VDB + Naive RAG\")\n",
    "]\n",
    "filtered_results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 237
    },
    "id": "LeTpO2C6L2tS",
    "outputId": "a6ca03e7-0a59-44f7-bb41-842615097ec0"
   },
   "outputs": [],
   "source": [
    "# Focus on experiments for a detailed comparison\n",
    "experiments_focus_group1 = [\n",
    "    \"Classic VDB + HyDE\",\n",
    "    \"Classic VDB + HyDE + Cohere Rerank\",\n",
    "    \"Classic VDB + HyDE + LLM Rerank\",\n",
    "    \"Classic VDB + LLM Rerank\"\n",
    "]\n",
    "\n",
    "filtered_results = tukey_result_df[\n",
    "    tukey_result_df['group1'].isin(experiments_focus_group1) &\n",
    "    tukey_result_df['group2'].isin(experiments_focus_group1)\n",
    "]\n",
    "filtered_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oxwOfQi_-tfb"
   },
   "source": [
    "### Tukey - best classic vdb vs worst sentence window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 81
    },
    "id": "s3oG3P-8n-Ov",
    "outputId": "0ac1ef3d-2266-4df6-af6d-ff2d80c7f2cc"
   },
   "outputs": [],
   "source": [
    "# Filter the original Tukey HSD results DataFrame to include only comparisons between the two experiments of interest\n",
    "filtered_results = tukey_result_df[\n",
    "    ((tukey_result_df['group1'] == \"Classic VDB + HyDE + LLM Rerank\") & (tukey_result_df['group2'] == \"Sentence window retrieval + Cohere rerank\")) |\n",
    "    ((tukey_result_df['group1'] == \"Sentence window retrieval + Cohere rerank\") & (tukey_result_df['group2'] == \"Classic VDB + HyDE + LLM Rerank\"))\n",
    "]\n",
    "\n",
    "# Display the filtered results\n",
    "filtered_results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Tc9KwTnv_kK2"
   },
   "source": [
    "### Tukey - Sentence Window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 175
    },
    "id": "8mINcBuMsnDg",
    "outputId": "2b9a89ee-0712-411f-90d2-f8aaff24ce4c"
   },
   "outputs": [],
   "source": [
    "# Filter the Tukey HSD results for comparisons involving \"Sentence window retrieval\"\n",
    "filtered_results = tukey_result_df[\n",
    "    (tukey_result_df['group1'] == \"Sentence window retrieval\")\n",
    "]\n",
    "\n",
    "filtered_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3ZtriZtk-frH"
   },
   "source": [
    "### Tukey - Doc summary vs Classic VDB vs Sentence window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rdIEqiojubR6",
    "outputId": "3f004634-f855-4db9-c224-af056cc7aebc"
   },
   "outputs": [],
   "source": [
    "# Filter for broader comparisons across selected experiments\n",
    "filtered_results = tukey_result_df[\n",
    "    tukey_result_df['group1'].isin([\n",
    "        \"Sentence window retrieval\",\n",
    "        \"Classic VDB + Naive RAG\",\n",
    "        \"Document summary index + Cohere Rerank\"\n",
    "    ]) & tukey_result_df['group2'].isin([\n",
    "        \"Sentence window retrieval\",\n",
    "        \"Classic VDB + Naive RAG\",\n",
    "        \"Document summary index + Cohere Rerank\"\n",
    "    ])\n",
    "]\n",
    "print(filtered_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Z2Yu2e3r-WRY"
   },
   "source": [
    "### Tukey - Doc summary techniques comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 81
    },
    "id": "DAyJm9EK1odO",
    "outputId": "726e7cad-864e-4dcd-e0ea-f3234ab27d17"
   },
   "outputs": [],
   "source": [
    "# Specific pairwise comparison\n",
    "filtered_results = tukey_result_df[\n",
    "    (tukey_result_df['group1'] == \"Document summary index + Cohere Rerank\") &\n",
    "    (tukey_result_df['group2'] == \"Document summary index + HyDE + Cohere Rerank\")\n",
    "]\n",
    "filtered_results\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
